# SALT 26 admin

This page documents the administration of SALT 26.
The main SALT 26 website is available at [salt.ling.utexas.edu/26](http://salt.ling.utexas.edu/26/).


## Abstract submission and review process

### Topics

We provided the option of selecting multiple topics out of the following list:

* Acquisition of meaning
* Anaphora and ellipsis
* Attitudes & intentionality
* Comparatives and superlatives
* Compositionality
* Computational semantics
* Conditionals
* Conjunction and/or disjunction
* Corpus-based semantics
* Definiteness, indefiniteness and specificity
* Diachronic semantics
* Dialogue semantics
* Discourse structure
* Dynamic Semantics & DRT
* Evidentiality
* Exclusives and additives
* Exhaustivity and maximality
* Existential constructions
* Experimental semantics and pragmatics
* Field-based semantics and semantics of underrepresented languages
* Genericity and kinds
* History of semantics and pragmatics
* Imperatives
* Implicature
* Indexicality and deixis
* Information Structure
* Lexical Semantics, thematic structure
* Mereology
* Modality
* Modifiers (adjectives, adverbs)
* Plurality and distributivity
* Polarity / Negation
* Possessives
* Quantification and scope
* Questions and interrogatives
* Quotation
* Scalarity, degree semantics
* Semantics of signed language
* Semantic processing
* Social meaning
* Speech acts and performativity
* Temporality (Tense, aspect)
* Typology and variation
* Vagueness and gradability

"Semantics of signed language" was added on 2015-12-01.

We considered "Neurolinguistic semantics" as a topic, but decided it wasn't enough of a thing except in the non-linguistic context of neuro-linguistic programming.


### Special session topics

For the special session on presupposition, we offered the following topics in a subsequent section:

* Anaphoric presupposition
* Corpus approaches to presupposition
* Cross-linguistic approaches to presupposition
* Definiteness presuppositions
* Diagnostics for presupposition
* Experimental approaches to presupposition
* Factive presuppositions
* Logics of presupposition
* Pragmatic presupposition
* Presupposition & conventional implicature
* Presupposition & focus
* Presupposition & quantification
* Presupposition accommodation
* Presupposition projection
* Presuppositional scales (Maximize presupposition)
* Variation between presupposition triggers (e.g. hard vs. soft)


### Emails

Templates for the various emails we delivered to authors and reviewers are available in the [email](email/) folder.

- **2015-11-24** [reviewer-invitation.txt](email/reviewer-invitation.txt): The "SALT 26 - Invitation to review" personal email was sent out to our mailing list of semantics contacts.
- **2015-12-20** [topics-needed.txt](email/topics-needed.txt): The "SALT 26 - reviewing assignments - topics needed!" EasyChair notification was sent out to reviewers who had not self-assigned any topics on EasyChair.
- **2015-12-23** [assignments.txt](email/assignments.txt): The "SALT 26 paper assignment" EasyChair notification was sent out to all reviewers.
- **2016-01-13** [author-response-reminder.txt](email/author-response-reminder.txt): The "Upcoming author response period (January 23-29)" EasyChair notification was sent out to 241 authors (those that were marked as the "corresponding" authors) of 182 papers.
- **2016-01-15** [reviewing-reminder.txt](email/reviewing-reminder.txt): The "SALT reviewing reminder (due January 22!)" EasyChair notification was sent out to all reviewers.
- **2016-01-19** [reviewer-trouble.txt](email/reviewer-trouble.txt): The "SALT 26 - Reviewing (are you OK?)" personal email was sent out to a dozen reviewers who had never logged into EasyChair (at least not the SALT site).
- **2016-01-19** [review-reminder-2.txt](email/review-reminder-2.txt): The "SALT 26 review reminder" EasyChair notification was sent out to all reviewers who had logged in to EasyChair but not submitted any of their assigned reviews.
- **2016-01-23** [review-reminder-3.txt](email/review-reminder-3.txt): The "SALT 26 (final!?) review reminder" EasyChair notification was sent out to a couple dozen reviewers who had logged in to EasyChair in the last month or so, but had not submitted any of their assigned reviews.
- **2016-01-23** [author-notification.txt](email/author-notification.txt): The "SALT 26 review feedback available for submission #" EasyChair notification was sent out to 241 authors of 182 submissions.
- **2016-01-27** [author-notification-2.txt](email/author-notification-2.txt): The "SALT 26 author response period reminder; additional reviews in some cases" EasyChair notification was sent out to all authors.
- **2016-01-30** [reviewer-response.txt](email/reviewer-response.txt): The "SALT 26 author response ends; reviewer response begins" EasyChair notification was sent out to 276 reviewers (those that had previously submitted reviews).
- **2016-03-11** [program-announcement.txt](email/program-announcement.txt): The "SALT 26 Program Announcement" email was sent out to 632 addresses on the semantics mailing list (which now includes all of the EasyChair authors, "corresponding" or not).
- **2016-03-14** [accepted-abstract-request.txt](email/accepted-abstract-request.txt): The "SALT 26 Publicity" email was sent out to the 88 corresponding authors of 61 papers.
- **2016-07-05** [survey.txt](email/survey.txt): The "SALT 26 Survey" email was sent to 297 corresponding abstract authors and registered participants.
- **2016-07-26** [reviewing-thanks.txt](email/reviewing-thanks.txt): The "Thank you from SALT at UT Austin!!!" email was sent out to 277 active reviewers (including authors and registered participants, so there was some overlap with the previous survey email), and included the survey link.


### Considerations when evaluating payment processors

(Extracted from an email thread from mid-February 2016)

The UT-internal service "TX Shop" is what we used for [NASSLLI 2012](http://nasslli2012.com/) and it was a pain to set up and explain on the NASSLLI registration page, but reliable enough once it was up and people were told exactly how to use it. I forget what fee we paid then, but they would charge a flat $700 setup fee for setting up a new "shop" for SALT registrations.

[PayPal](https://www.paypal.com/webapps/mpp/merchant-fees), [Square](https://squareup.com/online-store), and [Stripe](https://stripe.com/us/pricing) are all solid online payment processors that operate at our (small) scale, and all charge 2.9% + $0.30 per sale. PayPal has a slightly lower rate for non-profits (2.2% + $0.30), but it's unclear if that'd apply to us, and Square currently has a promo for online sales (2.75% + $0.30). [TLS](http://tls.ling.utexas.edu/) has been using PayPal since 2012 (four conferences so far), and in my experience, it works great for that.

If we wanted something specialized for event registration, [EventBrite](https://www.eventbrite.com/fees/) charges 5.5% + $0.99.

* Stanford used [Certain](https://www.certain.com/event-management/online-registration/), which I've never heard of before, and which doesn't specify their fees on their public website. I get the impression Stanford has an ongoing deal with them, based on Stanford + Certain search results.
* I can't tell what NYU (SALT 24 in 2014) used.
* UCSC (SALT 23 in 2013) isn't even loading for me right now and the WayBack Machine didn't capture their payment page, but it looks like something internal to UCSC.
* UChicago's (SALT 22 in 2012) registration page has only dead links.
* Rutgers (SALT 21 in 2011) used PayPal.
* Simon Fraser's (SALT 20 in 2010) registration form has been closed, but it looks internal to SFU.

Just as a ballpark estimate, if we charge what Stanford did — $40 / student, $80 / faculty for the early-bird rate — and have 50 students and 50 faculty register, that's $6000. PayPal's (or the others') fees would add up to $204.

Under the same ballpark estimate ($6000 of fees across 100 transactions), EventBrite would cost $429. But I don't think we need any of the additional features of EventBrite, like discount codes or availability periods.

**Results and rationale**

Despite EventBrite's exorbitant fees (more than twice those of other processors), we ended up going with them because they have an option to mail you a physical check a week or two after the end of the payment period, which is convenient.

* We did use their cut-off date functionality for early-bird registrations, but that could easily have been done, e.g. on PayPal, by logging on and changing the names and prices of the two products (student vs. faculty) on that date.
* We didn't use any of their other event-oriented functionality, like discount codes or ticket scanning on-site.
* We did process a number of refunds and changed some of the ordering data manually, which was easy, but again, I expect those basic tasks on other platforms are similarly easy.

Finally, my EventBrite fees estimate ended up only $18 off what we actually paid in fees.


### Survey

The survey was based on NYU's 2014 survey, and administered via [Qualtrics](https://utexas.qualtrics.com/).
The exported schema (not data) of the final version, in Qualtrics format, is available at [`survey.qsf`](survey.qsf).

There are four blocks/pages:

1. Demographics, shown to everyone, asking for conference participation level, academic status, and gender
2. Conference details, shown if the participation level was "Conference attendee"
3. Review process, shown if the participation level was "Abstract author" or "Author reviewer"
4. Final page, shown to everyone, asking about the special session


### Misc. Comments / Advice

* Even if all the relevant information is online, or in an email, people love printouts. Here's some of the stuff we printed and made available at the registration desk:
  - Wi-fi access information
  - Public URL to shared Box.com folder
  - Campus map with relevant buildings & nearby parking highlighted
  - Full program on single page, 2-up and double-sided (it was handy to have a print-friendly program on the website for this purpose)
* Deadlines:
  - Even if there is no hard deadline, practically, make one up. People love deadlines.
  - If you want to receive an email by the time X rolls around, choose your wording carefully. "Email it to us before X" seems to confuse some people. "Email it to us by (X-1)" or "Email it to us. Deadline: (X-1)" works better.
  - Depending on the purpose, a lot of people will be late. Box.com's "Email to upload" feature is really handy, so that you don't have to worry about transferring last-minute email attachments to the presentation console.
  - Box.com can be configured to send confirmations for each emailed file. People love confirmations that they did something.
  - If you do ask for submissions to be emailed, you might periodically remind people that saving an email to their 'Drafts' folder does not count as sending it to you. Manually replying to every incoming email to confirm is infeasible, and anyway, email is one of the most reliable forms of communication (apart from user error).
  - If you can figure out a way to say "even if you miss the deadline, send it along anyway and we can probably still make it work" without softening the sense of deadline, that might allay some time-consuming questions. For example, it's much easier to handle a late submission than to reply to an email saying "I'm sorry! I realize I'm late but can I still submit?" (_sans_ attachment) and subsequently handle an even later submission.
* Despite having recently entered the 21st century, A/V is still finicky.
  - Have a dedicated laptop for presentation purposes
    + Have it plugged in, so that it can just sit there all day
    + On-the-fly fixes: the snappier the better. If you're getting a loaner laptop, get something that's new and fast. It's not a single point of failure, since laptops are a commodity, but mending the failure takes (wastes) time.
    + This also helps ensure there are no time-wasting scrambles to find the appropriate video adapter or power sources
    + Strongly suggest that all presenters submit their slides beforehand. See above about deadlines and Box.com.
  - Sync a Dropbox / Box.com folder on that machine. The cloud / web is a far more trustworthy and fluid information transmission device than any presentation setup (as long as you have wi-fi).
* Lightning talks:
  - Don't allow people to zoom/pan on their slides. This confuses Preview.app / Acrobat Reader, and disrupts subsequent presenters (though, of the two, Reader makes it marginally easier to recover from this). This can be part of the instructions, or by only giving the lightning talk presenters a slide clicker, rather than access to the presentation device desktop.
* Organization:
  - Figure out what people plan to do during their session, so that you know to pester them to submit their slides if they want to show slides.
  - Even if you make it crystal clear how submitted files should be named, lots of people will find it difficult to follow these kinds of directions. I'm beginning to think there should be a sort of administrative checklist, where people can check whether they have satisfied some requirement, and would be responsible for ensuring that it's checked before some deadline.
    + Part of that admin back-end could be automated, where somebody's "talk is uploaded correctly" box doesn't get checked until there's a file with the proper name in the proper folder.
    + For something that can't be automated, e.g., someone's "has been awarded scholarship" box, that would be configurable manually by one of the administrators.
